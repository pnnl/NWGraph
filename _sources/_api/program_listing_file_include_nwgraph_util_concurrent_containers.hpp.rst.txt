
.. _program_listing_file_include_nwgraph_util_concurrent_containers.hpp:

Program Listing for File concurrent_containers.hpp
==================================================

|exhale_lsh| :ref:`Return to documentation for file <file_include_nwgraph_util_concurrent_containers.hpp>` (``include/nwgraph/util/concurrent_containers.hpp``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   
   #ifndef NW_GRAPH_CONCURRENT_CONTAINERS_HPP
   #define NW_GRAPH_CONCURRENT_CONTAINERS_HPP
   
   #include "nwgraph/util/backend.hpp"
   
   #include <atomic>
   #include <cstddef>
   #include <mutex>
   #include <vector>
   
   #if defined(NWGRAPH_BACKEND_HPX)
     #include <hpx/synchronization/mutex.hpp>
     #include <hpx/synchronization/spinlock.hpp>
     // HPX doesn't have concurrent_vector, we'll use a mutex-protected vector
   #else
     #include <tbb/concurrent_queue.h>
     #include <tbb/concurrent_vector.h>
     #include <tbb/queuing_mutex.h>
   #endif
   
   namespace nw {
   namespace graph {
   
   template <typename T>
   class concurrent_queue {
   public:
     using value_type = T;
   
     concurrent_queue() = default;
   
     void push(const T& item) {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       queue_.push(item);
   #else
       queue_.push(item);
   #endif
     }
   
     void push(T&& item) {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       queue_.push(std::move(item));
   #else
       queue_.push(std::move(item));
   #endif
     }
   
     bool try_pop(T& item) {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       if (queue_.empty()) {
         return false;
       }
       item = std::move(queue_.front());
       queue_.pop();
       return true;
   #else
       return queue_.try_pop(item);
   #endif
     }
   
     bool empty() const {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       return queue_.empty();
   #else
       return queue_.empty();
   #endif
     }
   
     void clear() {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       std::queue<T> empty;
       std::swap(queue_, empty);
   #else
       queue_.clear();
   #endif
     }
   
   private:
   #if defined(NWGRAPH_BACKEND_HPX)
     std::queue<T> queue_;
     mutable hpx::spinlock mutex_;
   #else
     tbb::concurrent_queue<T> queue_;
   #endif
   };
   
   template <typename T>
   class concurrent_vector {
   public:
     using value_type = T;
     using size_type = std::size_t;
     using reference = T&;
     using const_reference = const T&;
   
   #if defined(NWGRAPH_BACKEND_HPX)
     using iterator = typename std::vector<T>::iterator;
     using const_iterator = typename std::vector<T>::const_iterator;
   #else
     using iterator = typename tbb::concurrent_vector<T>::iterator;
     using const_iterator = typename tbb::concurrent_vector<T>::const_iterator;
   #endif
   
     concurrent_vector() = default;
   
     explicit concurrent_vector(size_type n) : data_(n) {}
   
     concurrent_vector(size_type n, const T& val) : data_(n, val) {}
   
     void push_back(const T& item) {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       data_.push_back(item);
   #else
       data_.push_back(item);
   #endif
     }
   
     void push_back(T&& item) {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       data_.push_back(std::move(item));
   #else
       data_.push_back(std::move(item));
   #endif
     }
   
     size_type size() const {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       return data_.size();
   #else
       return data_.size();
   #endif
     }
   
     bool empty() const {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       return data_.empty();
   #else
       return data_.empty();
   #endif
     }
   
     void clear() {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       data_.clear();
   #else
       data_.clear();
   #endif
     }
   
     void resize(size_type n) {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       data_.resize(n);
   #else
       data_.resize(n);
   #endif
     }
   
     void resize(size_type n, const T& val) {
   #if defined(NWGRAPH_BACKEND_HPX)
       std::lock_guard<hpx::spinlock> lock(mutex_);
       data_.resize(n, val);
   #else
       data_.resize(n, val);
   #endif
     }
   
     reference operator[](size_type i) {
       return data_[i];
     }
   
     const_reference operator[](size_type i) const {
       return data_[i];
     }
   
     iterator begin() { return data_.begin(); }
     iterator end() { return data_.end(); }
     const_iterator begin() const { return data_.begin(); }
     const_iterator end() const { return data_.end(); }
     const_iterator cbegin() const { return data_.cbegin(); }
     const_iterator cend() const { return data_.cend(); }
   
     T* data() { return data_.data(); }
     const T* data() const { return data_.data(); }
   
   private:
   #if defined(NWGRAPH_BACKEND_HPX)
     std::vector<T> data_;
     mutable hpx::spinlock mutex_;
   #else
     tbb::concurrent_vector<T> data_;
   #endif
   };
   
   class queuing_mutex {
   public:
     queuing_mutex() = default;
   
     // Non-copyable
     queuing_mutex(const queuing_mutex&) = delete;
     queuing_mutex& operator=(const queuing_mutex&) = delete;
   
     class scoped_lock {
     public:
       explicit scoped_lock(queuing_mutex& m)
   #if defined(NWGRAPH_BACKEND_HPX)
         : lock_(m.mutex_)
   #else
         : lock_(m.mutex_)
   #endif
       {}
   
       // Non-copyable
       scoped_lock(const scoped_lock&) = delete;
       scoped_lock& operator=(const scoped_lock&) = delete;
   
     private:
   #if defined(NWGRAPH_BACKEND_HPX)
       std::unique_lock<hpx::mutex> lock_;
   #else
       tbb::queuing_mutex::scoped_lock lock_;
   #endif
     };
   
   private:
   #if defined(NWGRAPH_BACKEND_HPX)
     hpx::mutex mutex_;
   #else
     tbb::queuing_mutex mutex_;
   #endif
   };
   
   class spinlock {
   public:
     spinlock() = default;
   
     // Non-copyable
     spinlock(const spinlock&) = delete;
     spinlock& operator=(const spinlock&) = delete;
   
     void lock() {
   #if defined(NWGRAPH_BACKEND_HPX)
       lock_.lock();
   #else
       while (flag_.test_and_set(std::memory_order_acquire)) {
         // Spin
       }
   #endif
     }
   
     void unlock() {
   #if defined(NWGRAPH_BACKEND_HPX)
       lock_.unlock();
   #else
       flag_.clear(std::memory_order_release);
   #endif
     }
   
     bool try_lock() {
   #if defined(NWGRAPH_BACKEND_HPX)
       return lock_.try_lock();
   #else
       return !flag_.test_and_set(std::memory_order_acquire);
   #endif
     }
   
   private:
   #if defined(NWGRAPH_BACKEND_HPX)
     hpx::spinlock lock_;
   #else
     std::atomic_flag flag_ = ATOMIC_FLAG_INIT;
   #endif
   };
   
   }    // namespace graph
   }    // namespace nw
   
   #endif    // NW_GRAPH_CONCURRENT_CONTAINERS_HPP
