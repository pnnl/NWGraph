
.. _program_listing_file_include_nwgraph_util_atomic.hpp:

Program Listing for File atomic.hpp
===================================

|exhale_lsh| :ref:`Return to documentation for file <file_include_nwgraph_util_atomic.hpp>` (``include/nwgraph/util/atomic.hpp``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   
   #ifndef NW_GRAPH_ATOMIC
   #define NW_GRAPH_ATOMIC
   
   #include "nwgraph/util/traits.hpp"
   #include <atomic>
   #include <type_traits>
   
   namespace nw {
   namespace graph {
   template <std::memory_order order, class T>
   constexpr auto load(T&& t) {
     if constexpr (is_atomic_v<std::decay_t<T>>) {
       return std::forward<T>(t).load(order);
     } else {
       return load<order>(std::atomic_ref(t));
     }
   }
   
   template <std::memory_order order, class T, class U>
   constexpr void store(T&& t, U&& u) {
     if constexpr (is_atomic_v<std::decay_t<T>>) {
       std::forward<T>(t).store(std::forward<U>(u), order);
     } else {
       store<order>(std::atomic_ref(t), std::forward<U>(u));
     }
   }
   
   template <std::memory_order success = std::memory_order_acq_rel, std::memory_order failure = std::memory_order_acquire, class T, class U,
             class V>
   constexpr bool cas(T&& t, U&& u, V&& v) {
     if constexpr (is_atomic_v<std::decay_t<T>>) {
       return std::forward<T>(t).compare_exchange_strong(std::forward<U>(u), std::forward<V>(v), success, failure);
     } else {
       return cas<success, failure>(std::atomic_ref(t), std::forward<U>(u), std::forward<V>(v));
     }
   }
   
   template <class T>
   constexpr auto acquire(T&& t) {
     return load<std::memory_order_acquire>(std::forward<T>(t));
   }
   
   template <class T>
   constexpr auto relaxed(T&& t) {
     return load<std::memory_order_relaxed>(std::forward<T>(t));
   }
   
   template <class T, class U>
   constexpr void release(T&& t, U&& u) {
     store<std::memory_order_release>(std::forward<T>(t), std::forward<U>(u));
   }
   
   template <class T, class U>
   constexpr void relaxed(T&& t, U&& u) {
     store<std::memory_order_relaxed>(std::forward<T>(t), std::forward<U>(u));
   }
   
   template <std::memory_order order = std::memory_order_acq_rel, class T, class U>
   constexpr auto fetch_add(T&& t, U&& u) {
     if constexpr (is_atomic_v<std::decay_t<T>>) {
       if constexpr (std::is_floating_point_v<remove_atomic_t<std::decay_t<T>>>) {
         auto&& e = acquire(t);
         while (!cas<order>(std::forward<T>(t), e, e + u))
           ;
         return e;
       } else {
         return t.fetch_add(std::forward<U>(u), order);
       }
     } else {
       // fallback to compiler atomics here... C++20 has atomic_ref.
       if constexpr (std::is_floating_point_v<std::decay_t<T>>) {
         auto e = acquire(std::forward<T>(t));
         for (auto f = e + u; !cas<order>(std::forward<T>(t), e, f); f = e + u)
           ;
         return e;
       } else {
         return fetch_add<order>(std::atomic_ref(t), std::forward<U>(u));
       }
     }
   }
   
   template <std::memory_order order = std::memory_order_acq_rel, class T, class U>
   constexpr auto fetch_or(T&& t, U&& u) {
     static_assert(!std::is_floating_point_v<std::decay_t<T>>, "Logical fetch_or invalid for floating point types.");
     if constexpr (is_atomic_v<std::decay_t<T>>) {
       return std::forward<T>(t).fetch_or(std::forward<U>(u), order);
     } else {
       return fetch_or<order>(std::atomic_ref(t), std::forward<U>(u));
     }
   }
   }    // namespace graph
   }    // namespace nw
   
   #endif    // NW_GRAPH_ATOMIC_HPP
